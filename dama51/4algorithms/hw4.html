<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <meta name="generator" content="Pelican"/>
    <title>Topics Analysis from HW4.docx</title>
    <link rel="stylesheet" href="/dama51/theme/css/main.css"/>
    <script>
        MathJax = {
            tex: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]],
                displayMath: [["$$", "$$"], ["\\[", "\\]"]],
                processEscapes: true
            },
            svg: {
                fontCache: "global"
            },
            options: {
                enableMenu: false  // Disable right-click MathJax menu
            }
        };
    </script>
    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


        <meta name="description" content="HW4" />
</head>

<style>
    :root {
        --background-image-uri: url("/dama51/images/background.png");
    }
</style>


<body id="index" class="home">
<header id="banner" class="body">
    <h1><a href="/dama51/">DAMA51</a>
    </h1>
    <nav>
        <ul>
            <li
><a href="/dama51/1introduction.html">1.Introduction</a></li>
            <li
><a href="/dama51/2various-topics.html">2.Various Topics</a></li>
            <li
><a href="/dama51/3foundations.html">3.Foundations</a></li>
            <li
 class="active"><a href="/dama51/4algorithms.html">4.Algorithms</a></li>
        </ul>
    </nav>
</header><!-- /#banner -->

<section id="content" class="body">
  <article>
      <header>
        <h1 class="entry-title">
          <a href="/dama51/4algorithms/hw4.html" rel="bookmark"
             title="Permalink to Topics Analysis from HW4.docx">Topics Analysis from HW4.docx</a></h1>
      </header>

      <div class="entry-content">
        <p>The HW4 assignment covers the following topics in <strong>Machine Learning (ML)</strong> and <strong>Data Analysis (DA)</strong>:</p>
<ol>
<li>
<p><strong>Decision Trees (ML)</strong></p>
<ul>
<li>Entropy and Information Gain calculations.</li>
<li>Implementation of the ID3 algorithm in R.</li>
<li>Building and visualizing a decision tree from a dataset.</li>
</ul>
</li>
<li>
<p><strong>Bayes Classifier (ML)</strong></p>
<ul>
<li>Probabilistic calculations for NaÃ¯ve Bayes classification.</li>
<li>Implementation of a NaÃ¯ve Bayes classifier in R.</li>
<li>Making predictions for new instances.</li>
</ul>
</li>
<li>
<p><strong>Itemset Mining &amp; Association Rules (DA/ML)</strong></p>
<ul>
<li>Frequent itemset analysis using the Apriori algorithm.</li>
<li>Generating and analyzing association rules.</li>
<li>Visualizing the rules using lift and network graphs.</li>
</ul>
</li>
<li>
<p><strong>Online Quiz</strong></p>
<ul>
<li>Likely covering general ML and DA concepts.</li>
</ul>
</li>
<li>
<p><strong>Project (Open-ended)</strong></p>
<ul>
<li>This could involve applying ML and DA techniques in a practical scenario.</li>
</ul>
</li>
</ol>
<p>The assignment involves both <strong>theoretical and practical implementation</strong> in <strong>R</strong>, requiring entropy calculations, probability derivations, and coding solutions for decision trees, NaÃ¯ve Bayes classifiers, and association rule mining. Let me know if you need help with any specific topic!</p>
<p>To systematically approach the HW4 tasks in <strong>R</strong>, we should break them down into <strong>structured steps</strong> per topic. Below is a <strong>topic-wise plan</strong> with the key <strong>methods, functions, and approach</strong> for solving them.</p>
<hr>
<h3><strong>Structured Approach to Solving DAMA51 HW4 Tasks in R</strong></h3>
<h2><strong>ðŸ“Œ Topic 2: Decision Trees (ML)</strong></h2>
<p><strong>Goal:</strong> Build a decision tree for the given dataset, compute entropy, information gain, and implement ID3 algorithm in R.</p>
<h3><strong>Steps to Follow:</strong></h3>
<ul>
<li><strong>Load Dataset</strong><ul>
<li>Read <code>Tennis_final.csv</code> interactively.  </li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="n">file_path</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">file.choose</span><span class="p">()</span><span class="w"> </span>
<span class="w">   </span><span class="n">data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.csv</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s">&quot;,&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="nf">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>Compute Entropy</strong><ul>
<li>Define an entropy function using Shannonâ€™s formula.</li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="n">Entropy</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">vls</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">res</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">vls</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">vls</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">log2</span><span class="p">(</span><span class="n">vls</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">vls</span><span class="p">))</span>
<span class="w">     </span><span class="n">res</span><span class="p">[</span><span class="n">vls</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">0</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span>
<span class="w">     </span><span class="o">-</span><span class="nf">sum</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="w">   </span><span class="p">}</span>
</code></pre></div>

<ul>
<li><strong>Compute Information Gain for Each Attribute</strong><ul>
<li>Define a function to calculate <strong>Information Gain (IG)</strong>.</li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="n">InformationGain</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">table</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">table</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.data.frame.matrix</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="w">     </span><span class="n">entropyBefore</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">Entropy</span><span class="p">(</span><span class="nf">colSums</span><span class="p">(</span><span class="n">table</span><span class="p">))</span>
<span class="w">     </span><span class="n">s</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rowSums</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="w">     </span><span class="n">entropyAfter</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">s</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="n">table</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">Entropy</span><span class="p">))</span>
<span class="w">     </span><span class="n">entropyBefore</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">entropyAfter</span>
<span class="w">   </span><span class="p">}</span>
</code></pre></div>

<ul>
<li>
<p>Compute IG for <code>Outlook</code>, <code>Temperature</code>, and <code>Humidity</code>.</p>
</li>
<li>
<p><strong>Implement the ID3 Algorithm</strong></p>
<ul>
<li>Create recursive decision tree construction.</li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="n">TrID3</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="n">node</span><span class="o">$</span><span class="n">obsCount</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nrow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="w">     </span><span class="nf">if </span><span class="p">(</span><span class="nf">IsPure</span><span class="p">(</span><span class="n">data</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">child</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">node</span><span class="o">$</span><span class="nf">AddChild</span><span class="p">(</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[,</span><span class="w"> </span><span class="nf">ncol</span><span class="p">(</span><span class="n">data</span><span class="p">)]))</span>
<span class="w">       </span><span class="n">child</span><span class="o">$</span><span class="n">obsCount</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">nrow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="w">     </span><span class="p">}</span><span class="w"> </span><span class="n">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="n">ig</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sapply</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">data</span><span class="p">)[</span><span class="o">-</span><span class="nf">ncol</span><span class="p">(</span><span class="n">data</span><span class="p">)],</span><span class="w"> </span><span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span>
<span class="w">         </span><span class="nf">InformationGain</span><span class="p">(</span><span class="nf">table</span><span class="p">(</span><span class="n">data</span><span class="p">[,</span><span class="w"> </span><span class="n">x</span><span class="p">],</span><span class="w"> </span><span class="n">data</span><span class="p">[,</span><span class="w"> </span><span class="nf">ncol</span><span class="p">(</span><span class="n">data</span><span class="p">)])))</span>
<span class="w">       </span><span class="n">feature</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">ig</span><span class="p">)[</span><span class="nf">which.max</span><span class="p">(</span><span class="n">ig</span><span class="p">)]</span>
<span class="w">       </span><span class="n">node</span><span class="o">$</span><span class="n">feature</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">feature</span>
<span class="w">       </span><span class="n">childObs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">split</span><span class="p">(</span><span class="n">data</span><span class="p">[,</span><span class="w"> </span><span class="o">!</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="o">%in%</span><span class="w"> </span><span class="n">feature</span><span class="p">)],</span><span class="w"> </span><span class="n">data</span><span class="p">[,</span><span class="w"> </span><span class="n">feature</span><span class="p">])</span>
<span class="w">       </span><span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="nf">seq_along</span><span class="p">(</span><span class="n">childObs</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">         </span><span class="n">child</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">node</span><span class="o">$</span><span class="nf">AddChild</span><span class="p">(</span><span class="nf">names</span><span class="p">(</span><span class="n">childObs</span><span class="p">)[</span><span class="n">i</span><span class="p">])</span>
<span class="w">         </span><span class="nf">TrID3</span><span class="p">(</span><span class="n">child</span><span class="p">,</span><span class="w"> </span><span class="n">childObs</span><span class="p">[[</span><span class="n">i</span><span class="p">]])</span>
<span class="w">       </span><span class="p">}</span>
<span class="w">     </span><span class="p">}</span>
<span class="w">   </span><span class="p">}</span>
</code></pre></div>

<ul>
<li><strong>Visualize the Decision Tree</strong></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;data.tree&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="nf">library</span><span class="p">(</span><span class="n">data.tree</span><span class="p">)</span>
<span class="w">   </span><span class="n">tree</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">Node</span><span class="o">$</span><span class="nf">new</span><span class="p">(</span><span class="s">&quot;Play&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="nf">TrID3</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">)</span>
<span class="w">   </span><span class="nf">print</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;feature&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;obsCount&quot;</span><span class="p">)</span>
</code></pre></div>

<hr>
<h2><strong>ðŸ“Œ Topic 3: Bayes Classifier (ML)</strong></h2>
<p><strong>Goal:</strong> Implement a <strong>NaÃ¯ve Bayes</strong> classifier in R.</p>
<h3><strong>Steps to Follow:</strong></h3>
<ul>
<li><strong>Load the dataset</strong></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="n">file_path</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">file.choose</span><span class="p">()</span>
<span class="w">   </span><span class="n">data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.csv</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s">&quot;,&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="n">data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data</span><span class="p">[,</span><span class="m">-1</span><span class="p">]</span><span class="w"> </span><span class="c1"># Remove &#39;Day&#39; column</span>
</code></pre></div>

<ul>
<li><strong>Install and Load the <code>naivebayes</code> Package</strong></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;naivebayes&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="nf">library</span><span class="p">(</span><span class="n">naivebayes</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>Train the NaÃ¯ve Bayes Model</strong></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="n">classifier</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">naive_bayes</span><span class="p">(</span><span class="n">PlayTennis</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">.</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>Make Predictions for Test Instances</strong></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="n">test1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">Outlook</span><span class="o">=</span><span class="s">&quot;Sunny&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Temperature</span><span class="o">=</span><span class="s">&quot;Mild&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Humidity</span><span class="o">=</span><span class="s">&quot;High&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Wind</span><span class="o">=</span><span class="s">&quot;Strong&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="n">prediction1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span><span class="w"> </span><span class="n">test1</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="nf">print</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">prediction1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">))</span>

<span class="w">   </span><span class="n">test2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">data.frame</span><span class="p">(</span><span class="n">Outlook</span><span class="o">=</span><span class="s">&quot;Overcast&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Temperature</span><span class="o">=</span><span class="s">&quot;Mild&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Humidity</span><span class="o">=</span><span class="s">&quot;Normal&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">Wind</span><span class="o">=</span><span class="s">&quot;Weak&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="n">prediction2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span><span class="w"> </span><span class="n">test2</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s">&quot;prob&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="nf">print</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">prediction2</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">))</span>
</code></pre></div>

<hr>
<h2><strong>ðŸ“Œ Topic 4: Itemset Mining &amp; Association Rules (DA)</strong></h2>
<p><strong>Goal:</strong> Use the Apriori algorithm for <strong>association rule mining</strong>.</p>
<h3><strong>Steps to Follow:</strong></h3>
<ul>
<li><strong>Install and Load Necessary Libraries</strong>  </li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;arules&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;arulesViz&quot;</span><span class="p">)</span>
<span class="w">   </span><span class="nf">library</span><span class="p">(</span><span class="n">arules</span><span class="p">)</span>
<span class="w">   </span><span class="nf">library</span><span class="p">(</span><span class="n">arulesViz</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>Load the Transaction Data</strong>  </li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="n">dataset</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.transactions</span><span class="p">(</span><span class="nf">file.choose</span><span class="p">(),</span><span class="w"> </span><span class="n">sep</span><span class="o">=</span><span class="s">&quot;,&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">rm.duplicates</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>Find the Top 5 Most Frequent Items</strong>  </li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="nf">itemFrequencyPlot</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="w"> </span><span class="n">topN</span><span class="o">=</span><span class="m">5</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>Run the Apriori Algorithm</strong>  </li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="n">rules</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">apriori</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="w"> </span>
<span class="w">                    </span><span class="n">parameter</span><span class="o">=</span><span class="nf">list</span><span class="p">(</span><span class="n">supp</span><span class="o">=</span><span class="m">0.01</span><span class="p">,</span><span class="w"> </span><span class="n">conf</span><span class="o">=</span><span class="m">0.4</span><span class="p">,</span><span class="w"> </span><span class="n">minlen</span><span class="o">=</span><span class="m">3</span><span class="p">))</span>
</code></pre></div>

<ul>
<li><strong>Extract Model Parameters</strong>  </li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="nf">summary</span><span class="p">(</span><span class="n">rules</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>Visualize the Rules</strong>  </li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="nf">inspect</span><span class="p">(</span><span class="nf">head</span><span class="p">(</span><span class="nf">sort</span><span class="p">(</span><span class="n">rules</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="o">=</span><span class="s">&quot;lift&quot;</span><span class="p">),</span><span class="w"> </span><span class="m">10</span><span class="p">))</span>
<span class="w">   </span><span class="nf">plot</span><span class="p">(</span><span class="n">rules</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="o">=</span><span class="s">&quot;graph&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">engine</span><span class="o">=</span><span class="s">&quot;htmlwidget&quot;</span><span class="p">)</span>
</code></pre></div>

<ul>
<li><strong>Find the Best-Selling Product</strong>  </li>
</ul>
<div class="highlight"><pre><span></span><code><span class="w">   </span><span class="nf">itemFrequencyPlot</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="w"> </span><span class="n">topN</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">&quot;Best-Selling Product&quot;</span><span class="p">)</span>
</code></pre></div>

<hr>
<h2><strong>ðŸ“Œ Topic 5: Project</strong></h2>
<p><strong>Goal:</strong> Special track â€“ may involve a mix of decision trees, Bayes classification, and association rules.</p>
<p><strong>Suggested Approach:</strong><br>
1. <strong>Identify the problem statement</strong> (e.g., predicting customer purchases, optimizing marketing strategies).<br>
2. <strong>Prepare and clean data</strong> (handle missing values, categorical encoding).<br>
3. <strong>Choose the right ML technique</strong> (Decision Trees for classification, Bayes for probabilistic modeling, Apriori for recommendations).<br>
4. <strong>Implement and evaluate the model</strong> (use cross-validation, accuracy metrics).<br>
5. <strong>Summarize findings and conclusions</strong>.  </p>
<hr>
<h2><strong>âœ… Summary of R Packages &amp; Functions Used</strong></h2>
<table>
<thead>
<tr>
<th>Task</th>
<th>Package</th>
<th>Key Functions</th>
</tr>
</thead>
<tbody>
<tr>
<td>Decision Trees</td>
<td><code>data.tree</code></td>
<td><code>Entropy()</code>, <code>InformationGain()</code>, <code>TrID3()</code></td>
</tr>
<tr>
<td>NaÃ¯ve Bayes</td>
<td><code>naivebayes</code></td>
<td><code>naive_bayes()</code>, <code>predict()</code></td>
</tr>
<tr>
<td>Association Rules</td>
<td><code>arules</code>, <code>arulesViz</code></td>
<td><code>apriori()</code>, <code>inspect()</code>, <code>itemFrequencyPlot()</code>, <code>plot()</code></td>
</tr>
</tbody>
</table>
<p>This <strong>structured approach</strong> ensures <strong>step-by-step completion</strong> of HW4 tasks while maintaining best practices in R. Let me know if you need any <strong>code explanations or modifications!</strong> ðŸš€</p>
      </div><!-- /.entry-content -->
  </article>
</section>


</body>
</html>